{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyamnewale/basic-NLP/blob/main/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenization"
      ],
      "metadata": {
        "id": "QolMw09Tf0Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab') # Download the missing 'punkt_tab' resource"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPXsv_yIbNX3",
        "outputId": "711f2573-d6aa-4853-b457-6da304bee2a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"Hello Welcome, to my notebook's.\n",
        "This notebook is related to tokenization NLP.\n",
        "\"\"\"\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "## Tokenization\n",
        "##sentence -> paragraphs\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "documents = sent_tokenize(corpus)\n",
        "print(documents)\n",
        "\n",
        "## tokenization\n",
        "##paragraph -> words\n",
        "##sentence -> words\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "corpus_words = word_tokenize(corpus)\n",
        "print(corpus_words)\n",
        "\n",
        "sentences_words = []\n",
        "for sentence in documents:\n",
        "  words = word_tokenize(sentence)\n",
        "  sentences_words.append(words)\n",
        "print(sentences_words)\n",
        "\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "corpus_punct = wordpunct_tokenize(corpus)\n",
        "print(corpus_punct)\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "corpus_tree = tokenizer.tokenize(corpus)\n",
        "print(corpus_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izwpHYHkbVsR",
        "outputId": "ecb79ee0-aae2-454b-fdb8-323a2bcff5ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Welcome, to my notebook's.\n",
            "This notebook is related to tokenization NLP.\n",
            "\n",
            "[\"Hello Welcome, to my notebook's.\", 'This notebook is related to tokenization NLP.']\n",
            "['Hello', 'Welcome', ',', 'to', 'my', 'notebook', \"'s\", '.', 'This', 'notebook', 'is', 'related', 'to', 'tokenization', 'NLP', '.']\n",
            "[['Hello', 'Welcome', ',', 'to', 'my', 'notebook', \"'s\", '.'], ['This', 'notebook', 'is', 'related', 'to', 'tokenization', 'NLP', '.']]\n",
            "['Hello', 'Welcome', ',', 'to', 'my', 'notebook', \"'\", 's', '.', 'This', 'notebook', 'is', 'related', 'to', 'tokenization', 'NLP', '.']\n",
            "['Hello', 'Welcome', ',', 'to', 'my', \"notebook's.\", 'This', 'notebook', 'is', 'related', 'to', 'tokenization', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rK2FJBFMcebs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}